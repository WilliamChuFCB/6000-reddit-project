{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Word Cloud Generated by TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oc0KmrHYwrRr",
        "outputId": "49a53871-825d-463f-d525-89a388c1f1cd",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): done\n",
            "Solving environment: \\ \n",
            "The environment is inconsistent, please check the package plan carefully\n",
            "The following packages are causing the inconsistency:\n",
            "\n",
            "  - defaults/linux-64::anaconda-client==1.7.2=py37_0\n",
            "  - defaults/noarch::anaconda-project==0.8.4=py_0\n",
            "  - defaults/linux-64::bokeh==1.4.0=py37_0\n",
            "  - defaults/noarch::dask==2.11.0=py_0\n",
            "  - defaults/linux-64::distributed==2.11.0=py37_0\n",
            "  - defaults/linux-64::spyder==4.0.1=py37_0\n",
            "  - defaults/linux-64::watchdog==0.10.2=py37_0\n",
            "failed with initial frozen solve. Retrying with flexible solve.\n",
            "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): done\n",
            "Solving environment: / \n",
            "The environment is inconsistent, please check the package plan carefully\n",
            "The following packages are causing the inconsistency:\n",
            "\n",
            "  - defaults/linux-64::anaconda-client==1.7.2=py37_0\n",
            "  - defaults/noarch::anaconda-project==0.8.4=py_0\n",
            "  - defaults/linux-64::bokeh==1.4.0=py37_0\n",
            "  - defaults/noarch::dask==2.11.0=py_0\n",
            "  - defaults/linux-64::distributed==2.11.0=py37_0\n",
            "  - defaults/linux-64::spyder==4.0.1=py37_0\n",
            "  - defaults/linux-64::watchdog==0.10.2=py37_0\n",
            "done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /opt/conda\n",
            "\n",
            "  added / updated specs:\n",
            "    - openjdk\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2023.08.22 |       h06a4308_0         123 KB\n",
            "    certifi-2022.12.7          |   py37h06a4308_0         150 KB\n",
            "    conda-22.9.0               |   py37h06a4308_0         878 KB\n",
            "    openjdk-8.0.152            |       h7b6447c_3        57.4 MB\n",
            "    openssl-1.1.1w             |       h7f8727e_0         3.7 MB\n",
            "    pyyaml-5.3.1               |   py37h7b6447c_0         181 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        62.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  openjdk            pkgs/main/linux-64::openjdk-8.0.152-h7b6447c_3 None\n",
            "  pyyaml             pkgs/main/linux-64::pyyaml-5.3.1-py37h7b6447c_0 None\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    conda-forge::ca-certificates-2023.7.2~ --> pkgs/main::ca-certificates-2023.08.22-h06a4308_0 None\n",
            "  openssl            conda-forge::openssl-1.1.1l-h7f98852_0 --> pkgs/main::openssl-1.1.1w-h7f8727e_0 None\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  certifi            conda-forge/noarch::certifi-2023.7.22~ --> pkgs/main/linux-64::certifi-2022.12.7-py37h06a4308_0 None\n",
            "  conda              conda-forge::conda-22.9.0-py37h89c186~ --> pkgs/main::conda-22.9.0-py37h06a4308_0 None\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "openjdk-8.0.152      | 57.4 MB   | ##################################### | 100% \n",
            "pyyaml-5.3.1         | 181 KB    | ##################################### | 100% \n",
            "conda-22.9.0         | 878 KB    | ##################################### | 100% \n",
            "certifi-2022.12.7    | 150 KB    | ##################################### | 100% \n",
            "openssl-1.1.1w       | 3.7 MB    | ##################################### | 100% \n",
            "ca-certificates-2023 | 123 KB    | ##################################### | 100% \n",
            "Preparing transaction: done\n",
            "Verifying transaction: done\n",
            "Executing transaction: done\n",
            "Retrieving notices: ...working... done\n",
            "\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting pyspark==3.2.0\n",
            "  Using cached pyspark-3.2.0-py2.py3-none-any.whl\n",
            "Collecting py4j==0.10.9.2 (from pyspark==3.2.0)\n",
            "  Using cached py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<script>Jupyter.notebook.kernel.restart()</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setup - Run only once per Kernel App\n",
        "%conda install openjdk -y\n",
        "\n",
        "# install PySpark\n",
        "%pip install pyspark==3.2.0\n",
        "\n",
        "# restart kernel\n",
        "from IPython.core.display import HTML\n",
        "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1fczuAAwrRw",
        "outputId": "cfeecd54-3967-45d9-b8ed-eb849c968aee",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.2.0\n"
          ]
        }
      ],
      "source": [
        "# Import pyspark and build Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder.appName(\"PySparkApp\")\n",
        "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.2.2\")\n",
        "    .config(\n",
        "        \"fs.s3a.aws.credentials.provider\",\n",
        "        \"com.amazonaws.auth.ContainerCredentialsProvider\",\n",
        "    )\n",
        "    .getOrCreate()\n",
        ")\n",
        "\n",
        "print(spark.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3ulBGe7wrRy"
      },
      "source": [
        "## Process S3 data with SageMaker Processing Job `PySparkProcessor`\n",
        "\n",
        "We are going to move the above processing code in a Python file and then submit that file to SageMaker Processing Job's [`PySparkProcessor`](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_processing.html#pysparkprocessor)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Quk3JKP0wrRy",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!mkdir -p ./code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bn8qyvlwrRz",
        "outputId": "72996e36-cd5f-479a-d584-d2c030810351",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./code/process.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./code/process.py\n",
        "\n",
        "import os\n",
        "import logging\n",
        "import argparse\n",
        "\n",
        "# Import pyspark and build Spark session\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import (\n",
        "    DoubleType,\n",
        "    IntegerType,\n",
        "    StringType,\n",
        "    StructField,\n",
        "    StructType,\n",
        ")\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s,%(levelname)s,%(module)s,%(filename)s,%(lineno)d,%(message)s', level=logging.DEBUG)\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.DEBUG)\n",
        "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"app inputs and outputs\")\n",
        "    parser.add_argument(\"--s3_dataset_path\", type=str, help=\"Path of dataset in S3\")\n",
        "    parser.add_argument(\"--s3_output_bucket\", type=str, help=\"s3 output bucket\")\n",
        "    parser.add_argument(\"--s3_output_prefix\", type=str, help=\"s3 output prefix\")\n",
        "    parser.add_argument(\"--col_name_for_filtering\", type=str, help=\"Name of the column to filter\")\n",
        "    parser.add_argument(\"--values_to_keep\", type=str, help=\"comma separated list of values to keep in the filtered set\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    spark = SparkSession.builder.appName(\"PySparkApp\").getOrCreate()\n",
        "    logger.info(f\"spark version = {spark.version}\")\n",
        "\n",
        "    # This is needed to save RDDs which is the only way to write nested Dataframes into CSV format\n",
        "    sc = spark.sparkContext\n",
        "    sc._jsc.hadoopConfiguration().set(\n",
        "        \"mapred.output.committer.class\", \"org.apache.hadoop.mapred.FileOutputCommitter\"\n",
        "    )\n",
        "\n",
        "\n",
        "    # Downloading the data from S3 into a Dataframe\n",
        "    logger.info(f\"going to read {args.s3_dataset_path}\")\n",
        "    df = spark.read.parquet(args.s3_dataset_path, header=True)\n",
        "    logger.info(f\"finished reading files...\")\n",
        "\n",
        "\n",
        "\n",
        "    # filter the dataframe to only keep the values of interest\n",
        "    vals = [s.strip() for s in args.values_to_keep.split(\",\")]\n",
        "    df_filtered = df.where(col(args.col_name_for_filtering).isin(vals))\n",
        "\n",
        "    # save the filtered dataframes so that these files can now be used for future analysis\n",
        "    s3_path = f\"s3://{args.s3_output_bucket}/{args.s3_output_prefix}\"\n",
        "    logger.info(f\"going to write data for {vals} in {s3_path}\")\n",
        "    logger.info(f\"shape of the df_filtered dataframe is {df_filtered.count():,}x{len(df_filtered.columns)}\")\n",
        "    df_filtered.write.mode(\"overwrite\").parquet(s3_path)\n",
        "\n",
        "    logger.info(f\"all done...\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58eEzIUswrR1"
      },
      "source": [
        "Now submit this code to SageMaker Processing Job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB9Pn2GEwrR2",
        "outputId": "6e7b6980-dbbb-4d21-b469-600b95928e3d",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 2.36 s, sys: 208 ms, total: 2.57 s\n",
            "Wall time: 2.75 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import time\n",
        "import sagemaker\n",
        "from sagemaker.spark.processing import PySparkProcessor\n",
        "\n",
        "# Setup the PySpark processor to run the job. Note the instance type and instance count parameters. SageMaker will create these many instances of this type for the spark job.\n",
        "role = sagemaker.get_execution_role()\n",
        "spark_processor = PySparkProcessor(\n",
        "    base_job_name=\"sm-spark-project\",\n",
        "    framework_version=\"3.3\",\n",
        "    role=role,\n",
        "    instance_count=8,\n",
        "    instance_type=\"ml.m5.xlarge\",\n",
        "    max_runtime_in_seconds=3600,\n",
        ")\n",
        "\n",
        "# s3 paths\n",
        "session = sagemaker.Session()\n",
        "bucket = session.default_bucket()\n",
        "output_prefix_logs = f\"spark_logs\"\n",
        "\n",
        "# modify this comma separated list to choose the subreddits of interest\n",
        "subreddits = \"soccer\"\n",
        "configuration = [\n",
        "    {\n",
        "        \"Classification\": \"spark-defaults\",\n",
        "        \"Properties\": {\"spark.executor.memory\": \"12g\", \"spark.executor.cores\": \"4\"},\n",
        "    }\n",
        "]\n",
        "\n",
        "# the dataset contains data for these 3 years\n",
        "year_list = [2023]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NefjRBSxwrR5",
        "outputId": "0c4f696a-318a-4d86-d89c-13278441755f",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reading comments from s3a://sagemaker-us-east-1-019290627849/project/comments/yyyy=*\n",
            "shape of the comments dataframe is 2,255,511x21\n",
            "CPU times: user 186 ms, sys: 30.9 ms, total: 217 ms\n",
            "Wall time: 5min 29s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import sagemaker\n",
        "session = sagemaker.Session()\n",
        "bucket = session.default_bucket()\n",
        "output_prefix_data_comments = \"project/comments/yyyy=*\"\n",
        "s3_path = f\"s3a://{bucket}/{output_prefix_data_comments}\"\n",
        "#s3_path = \"s3a://sagemaker-us-east-1-038932893404/project/comments/yyyy=2021/part-00000-90796409-5783-4705-92c0-27c27eda8c4c-c000.snappy.parquet\"\n",
        "print(f\"reading comments from {s3_path}\")\n",
        "comments = spark.read.parquet(s3_path, header=True)\n",
        "print(f\"shape of the comments dataframe is {comments.count():,}x{len(comments.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XXgn1m7wrR_",
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_soccer = comments.filter(comments[\"subreddit\"] == \"soccer\").\\\n",
        "    select(\"body\", \"created_utc\").cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkUmpmYGwrSB",
        "outputId": "977d9791-0b77-447e-919e-0b8c0b251a05",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7097"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Subset the text\n",
        "\n",
        "df_sample = df_soccer.sample(False, fraction=0.01).cache()\n",
        "df_sample.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeadK0MKwrSF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import re\n",
        "import pyspark.sql.functions as f\n",
        "\n",
        "# clean the text with stopwords\n",
        "stopwords = ['s', 'one', 'u'] + list(STOPWORDS)\n",
        "\n",
        "def process_text(val):\n",
        "    comment_words = ''\n",
        "\n",
        "    tokens = val.split()\n",
        "    for i in range(len(tokens)):\n",
        "        tokens[i] = tokens[i].lower()\n",
        "    comment_words += \" \".join(tokens) + \" \"\n",
        "    return comment_words\n",
        "\n",
        "process_text_udf = f.udf(process_text)\n",
        "\n",
        "# apply the UDF to the clean the text\n",
        "df_sample = df_sample.withColumn(\"comment_words\", process_text_udf(f.col(\"body\"))).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHEUktW5wrSG",
        "outputId": "6a9aff07-dd1e-4c6e-900a-9adacc865ad6",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "# Download the WordNet data\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EliHTsMRwrSG",
        "outputId": "66074837-0091-46fd-b0b4-9bc63c1fbe19"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['doe'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# lemmatize the text\n",
        "df_sample['comment_words'] = df_sample['comment_words'].map(lambda x: re.sub(r'[^a-zA-Z ] ', ' ', str(x)))\n",
        "\n",
        "def remove_encoding_word(word):\n",
        "    word = str(word)\n",
        "    word = word.encode('ASCII', 'ignore').decode('ASCII')\n",
        "    return word\n",
        "\n",
        "def remove_encoding_text(text):\n",
        "    text = str(text)\n",
        "    text = ' '.join(remove_encoding_word(word) for word in text.split() if word not in stopwords)\n",
        "    return text\n",
        "\n",
        "df_sample['comment_words'] = df_sample['comment_words'].apply(remove_encoding_text)\n",
        "\n",
        "text = ' '.join(words for words in df_sample['comment_words'])\n",
        "len(text)\n",
        "\n",
        "lemma = WordNetLemmatizer().lemmatize\n",
        "\n",
        "#fit into the tf-idf model\n",
        "def tokenize(document):\n",
        "    tokens = [lemma(w) for w in document.split() if len(w) > 3 and w.isalpha()]\n",
        "    return tokens\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer = tokenize, ngram_range = ((2,2)), stop_words = stopwords, strip_accents = 'unicode')\n",
        "\n",
        "tdm = vectorizer.fit_transform(df_sample['comment_words'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWwEI9BqwrSG",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# generate data ready for word cloud\n",
        "\n",
        "tfidf_weights = [(word, tdm.getcol(idx).sum()) for word, idx in vectorizer.vocabulary_.items()]\n",
        "\n",
        "w = WordCloud(width=2000, height=1200, mode='RGBA', background_color='white', max_words=2000).fit_words(dict(tfidf_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73-vDDBewrSH",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# plot the word cloud\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20,12))\n",
        "plt.imshow(w)\n",
        "plt.axis('off')\n",
        "plt.savefig('recipes_wordcloud.png')"
      ]
    }
  ],
  "metadata": {
    "availableInstances": [
      {
        "_defaultOrder": 0,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.t3.medium",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 1,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.t3.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 2,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.t3.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 3,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.t3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 4,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 5,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 6,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 7,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 8,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 9,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 10,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 11,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 12,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5d.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 13,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5d.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 14,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5d.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 15,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5d.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 16,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5d.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 17,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5d.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 18,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5d.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 19,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 20,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": true,
        "memoryGiB": 0,
        "name": "ml.geospatial.interactive",
        "supportedImageNames": [
          "sagemaker-geospatial-v1-0"
        ],
        "vcpuNum": 0
      },
      {
        "_defaultOrder": 21,
        "_isFastLaunch": true,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.c5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 22,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.c5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 23,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.c5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 24,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.c5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 25,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 72,
        "name": "ml.c5.9xlarge",
        "vcpuNum": 36
      },
      {
        "_defaultOrder": 26,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 96,
        "name": "ml.c5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 27,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 144,
        "name": "ml.c5.18xlarge",
        "vcpuNum": 72
      },
      {
        "_defaultOrder": 28,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.c5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 29,
        "_isFastLaunch": true,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g4dn.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 30,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g4dn.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 31,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g4dn.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 32,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g4dn.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 33,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g4dn.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 34,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g4dn.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 35,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 61,
        "name": "ml.p3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 36,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 244,
        "name": "ml.p3.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 37,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 488,
        "name": "ml.p3.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 38,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.p3dn.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 39,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.r5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 40,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.r5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 41,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.r5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 42,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.r5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 43,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.r5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 44,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.r5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 45,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.r5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 46,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.r5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 47,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 48,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 49,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 50,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 51,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 52,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 53,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.g5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 54,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.g5.48xlarge",
        "vcpuNum": 192
      },
      {
        "_defaultOrder": 55,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 56,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4de.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 57,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.trn1.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 58,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.trn1.32xlarge",
        "vcpuNum": 128
      },
      {
        "_defaultOrder": 59,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.trn1n.32xlarge",
        "vcpuNum": 128
      }
    ],
    "colab": {
      "provenance": []
    },
    "instance_type": "ml.m5.xlarge",
    "kernelspec": {
      "display_name": "ANLY501",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
